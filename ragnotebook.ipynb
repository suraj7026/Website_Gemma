{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"llama3\"\n",
    "MODEL = \"gemma:7b\"\n",
    "MODEL = \"stablelm2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "model = ChatOllama(model = MODEL)\n",
    "embeddings = OllamaEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.invoke(\"Tell me a joke\")) # Completion model -> gemma:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = model | output_parser\n",
    "# print(chain.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Brain Tumor Detection Assistant (BTDA)Project Report\\nSudarshan R 21BAI1257Mukundh J 21BAI1133\\nProject Report1', metadata={'source': 'BTDA-Report.pdf', 'page': 0}),\n",
       " Document(page_content='Table of Contents Literature Review………………………………………………………………………………3 Problem Statement…………………………………………………………………………..4 Dataset………………………………………………………………………………………..……5 Model...............................................................6 Hyperparameters..............................................7 Coding...............................................................8 Performance Improvement.................................9 Execution.......................................................... 10 Results.............................................................11 Conclusion........................................................13 References........................................................14 \\nProject Report2', metadata={'source': 'BTDA-Report.pdf', 'page': 1}),\n",
       " Document(page_content='Literature Review \\nProject Report3S. NoCitations Paper TitleMethodologyResultsInference and Limitations\\n1Naseer A, Yasir T, Azhar A, Shakeel T, Zafar K -International Journal of Biomedical Imaging. 2021 Jun 13;2021.Computer-Aided Brain Tumor Diagnosis: Performance Evaluation of Deep Learner CNN Using Augmented Brain MRITo propose a computer-aided brain tumor diagnosis tool for early detection, improve the performance and accuracy of brain tumor diagnosis and compare the proposed CNN-based system with other existing systemsProposed CNN based CAD system achieves 98.91% correct diagnosis of Brain Tumour.Achieves 100% accuracy for two brain MRI DatasetsThe paper uses only 255 positive and 255 negative brain tumor MRIs for training the CNN model\\n \\n2Sarhan AM -Journal of Biomedical Science and Engineering. 2020 Jun 17;13(06):102. Brain Tumor Classiﬁcation in Magnetic Resonance Images Using Deep Learning and Wavelet TransformTo develop a brain cancer classiﬁcation system using Wavelet decomposition and CNNs. To classify three types of brain tumors(meningioma, glioma, and pituitary tumor).The proposed system achieved an overall accuracy of 99.3%.\\nThe SVM classiﬁer achieved an accuracy of 98.5%.\\nThe proposed system showed high sensitivity and speciﬁcity values, indicating robustness and The model was trained on a relatively small dataset of 510 images\\n3Mahmud MI, Mamun M, Abdelgawad A. - Algorithms. 2023 Mar 23;16(4):176. A Deep Analysis of Brain Tumor Detection from MR Images Using Deep Learning Networks.Uses convolutional neural network (CNN) architecture for efﬁcient brain tumor identiﬁcation and compare the performance of the proposed model with other models such as ResNet-50, VGG16, and Inception V3.Early detection of brain tumors is crucial for reducing mortality rates.Correct detection and classiﬁcation of brain tumors is challenging.Deep learning models, speciﬁcally CNN, show promise for early detection.Initial long processing time due to low GPU resources.Doesn’t incorporate individual patient information for better brain cancer identiﬁcationResNet-50 architecture may face issues like vanishing gradients with increased layers.\\n4Rajinikanth V, Kadry S, Nam Y. -Information Technology and Control. 2021 Jun 17;50(2):342-56. Convolutional-Neural-Network Assisted Segmentation and SVM Classiﬁcation of Brain Tumor in Clinical MRI SlicesDevelops a Computer Aided Disease Diagnosis (CADD) scheme for brain tumorsegmentation and classiﬁcation.Uses a Convolutional-Neural-Network (CNN) for segmentation and VGG16 for feature extraction.Implement binary classiﬁcation with SVM-Cubic for enhanced disease detection accuracy.Experimental investigation using benchmark and clinical MRI slices.Convolutional-Neural-Network (CNN) supported segmentation and classiﬁcation.SVM-Cubic achieved accuracy >98% in binary classiﬁcation.The ﬁreﬂy algorithm based feature selection involves a large number of iterations and evaluations which increases the computational cost and time', metadata={'source': 'BTDA-Report.pdf', 'page': 2}),\n",
       " Document(page_content='Project Report4S. NoCitationsPaper TitleMethodologyResultsInference and Limitations\\n5Saeedi S, Rezayi S, Keshavarz H, R. Niakan Kalhori S. - BMC Medical Informatics and Decision Making. 2023 Jan 23;23(1):16. MRI-based brain tumor detection using convolutional deep learning methods and chosen machine learning techniques\\nPreprocessing and augmentation algorithms were applied to MRI brain images.\\nTwo deep learning methods: 2D Convolutional Neural Network (CNN) and convolutional auto-encoder network were employed\\nProposed 2D CNN and auto-encoder network achieved high accuracy in classifying brain tumors.\\nMachine learning techniques (KNN, RF , SVM) also showed high accuracies.\\nProposed networks have optimal execution time and can be used in medical diagnostics.\\nThe paper used a dataset of 3264 MRI images, which may not be enough to train deep neural networks eﬀectively and generalize to diﬀerent types of brain tumors.\\n6Xiong S, Wu G, Fan X, Feng X, Huang Z, Cao W, Zhou X, Ding S, Yu J, Wang L, Shi Z. - BMC bioinformatics. 2021 Dec;22:1-5. MRI-based brain tumor segmentation using FPGA-accelerated neural network\\nThe methodology involves a CNN-based brain tumor segmentation process, where the training phase iteratively updates parameters for minimal diﬀerence, and the inference phase emphasizes real-time acceleration. This process includes the quantization of a 3D U-Net model for FPGA implementation.\\nAchieved 0.871 DSC and 0.882 DSC for brain tumor segmentation.\\nAverage execution time of 0.15s and FPGA energy consumption of 45W. \\nSuggested method provided accurate and eﬃcient segmentation results.\\nWide spatial distribution and uncertainty of gliomas pose challenges in locating brain tumors.\\nGPU-based brain tumor segmentation can be further improved in terms of speed and power consumption.\\n7Fouad IA. - Annals of the Romanian Society for Cell Biology. 2021 Dec 23;25(6):21040-55. Developing a fully automated CAD tool for eﬀective and accurate Detection of brain tumors in MRI images\\nInvolves pre-processing steps such as graylevel conversion, Wiener ﬁlter, median ﬁlter, and histogram equalization. Feature extraction is performed using Discrete Wavelet Transform (DWT) and Principal Component Analysis (PCA), followed by classiﬁcation using Random Forest, Kernel Support Vector Machine, and the Resnet-50 model.\\nThe Resnet-50 classiﬁer achieved the highest average classiﬁcation accuracy of 94.9123%.\\nThe proposed tool eﬀectively distinguishes between diﬀerent brain tumors.\\nThe tool was evaluated on 3420 brain MRI images and achieved high classiﬁcation success rates.\\nNumber of output classes can be maximized.\\nComputation time should be taken into consideration.', metadata={'source': 'BTDA-Report.pdf', 'page': 3}),\n",
       " Document(page_content='Project Report5S. NoCitationsPaper TitleMethodologyResultsInference and Limitations\\n8Anagun Y . -Multimedia Tools and Applications. 2023 Nov;82(28):44527-53 Smart brain tumordiagnosis system utilizing deep convolutional neural networks\\nEmploys a CNN-based system using the EﬃcientNetv2 model, improved with Ranger optimization and extensive pre-processing techniques like cropping, histogram equalization, and denoising. It’s experimentally evaluated with diﬀerent optimizers and compared with ResNet18, ResNet200d, and InceptionV4 architectures.\\nEﬃcientNetv2l achieved highest accuracy of 97.72% using augmentation.\\nRanger optimizer showed better performance with 98.60% test accuracy.\\nResNet18 and InceptionV4 achieved 99.62% and 99.69% accuracy respectively.\\nPre-processing for feature extraction is complicated and time-consuming.\\n9ZainEldin H, Gamel SA, El-Kenawy ES, Alharbi AH, Khafaga DS, Ibrahim A, Talaat FM. -Bioengineering. 2022 Dec 22;10(1):18. Brain Tumor Detection and Classiﬁcation Using Deep Learning and Sine-Cosine Fitness Grey Wolf OptimizationUtilizes a U-Net network for fast and accurate image segmentation, with a 3D U-Net variant employed for feature extraction and mask production. The system’s performance is compared with other classiﬁers including CNN, Decision Tree, Linear Discriminant, Support Vector Machine, and K-Nearest NeighborThe proposed Brain Tumor Classiﬁcation Model achieved 99.98% accuracy.•The model used the BRaTS2021 Task 1 dataset.•The model was optimized using the ADSCFGWO algorithm.The proposed algorithm takes a long time to process due to extra optimization steps.Can generalize more data and make predictions, not just classiﬁcation\\n10Chen T, Hu L, Lu Q, Xu H, Lu L. -Frontiers in Neuroscience. 2023 Jul 7;17:1120781. A computer-aided diagnosis system for brain tumors based on artiﬁcial intelligence algorithmsDevelops a Computer-Aided Diagnosis (CAD) system for the detection and grading of gliomas. This system employs a two-level histogram-based morphometry (HBM) classiﬁcation framework for accurate glioma diagnosis. Additionally, various machine learning models are trained for efﬁcient and precise glioma detection and grading.Glioma detection achieved an area under curve (AUC) of 0.921.Glioma grading achieved an AUC of 0.806.Glioma segmentation visualization using the Exp-seg algorithm.Segmentation algorithm cannot discriminate other brain areas related to tumors.•Exp-seg algorithm needs improvement for more accurate segmentation', metadata={'source': 'BTDA-Report.pdf', 'page': 4}),\n",
       " Document(page_content='Problem Statement Many patients lack direct access to and understanding of their medical imaging data. This can lead to feelings of uncertainty and hinder their ability to participate actively in their care. There is a need for a platform that empowers patients to engage with their medical scans while also streamlining the diagnostic process for healthcare providers. Dataset  Source: Brain Tumor MRI Dataset What is a brain tumor? A brain tumor is a collection, or mass, of abnormal cells in your brain. Your skull, which encloses your brain, is very rigid. Any growth inside such a restricted space can cause problems. Brain tumors can be cancerous (malignant) or noncancerous (benign). When benign or malignant tumors grow, they can cause the pressure inside your skull to increase. This can cause brain damage, and it can be life-threatening. This dataset is a combination of the following two datasets : •figshare •SARTAJ dataset This dataset contains\\xa07023\\xa0images of human brain MRI images which are classified into 4 classes:\\xa0glioma\\xa0-\\xa0meningioma\\xa0-\\xa0no tumor\\xa0and\\xa0pituitary.No tumor class images were taken from the Br35H dataset. Project Report6', metadata={'source': 'BTDA-Report.pdf', 'page': 5}),\n",
       " Document(page_content=\"The train and test split ratio is around 80:20, with 5712 images in train and 1311 images in test  Model Choice and Rationale In our brain tumor classification project, we employed a hybrid deep learning architecture combining a Convolutional Neural Network (CNN) with a Long Short-Term Memory (LSTM) layer. This design aims to eﬀectively analyze MRI scans for both image-based tumor classification and to provide patient-friendly explanations with the assistance of GEMMA's text generation capabilities. Strengths of Convolutional Neural Networks (CNNs): •Feature Extraction: CNNs excel at automatically learning relevant features directly from image data. This is crucial for brain tumor classification, as identifying subtle patterns and textures within the MRI scans is paramount for accurate diagnosis. •Spatial Invariance: Through pooling layers, CNNs can achieve spatial invariance. This means the model can recognize tumors even if their location within the MRI slightly varies. This robustness is essential for real-world applications where image acquisition might not always be perfectly standardized. Rationale for Including a Long Short-Term Memory (LSTM) Layer: We introduced an LSTM layer to investigate its potential benefits in these specific ways: •Capturing Sequential Relationships: MRI scans often consist of multiple slices that capture diﬀerent sections of the brain. The LSTM layer, with its ability to process data in a sequential manner, can learn subtle relationships between these slices that might be informative for tumor classification. Project Report7\", metadata={'source': 'BTDA-Report.pdf', 'page': 6}),\n",
       " Document(page_content=\"Synergy with GEMMA By integrating the image classification model with GEMMA's text generation capabilities, we aim to bridge the information gap between technical diagnoses and patient understanding. The model not only classifies brain tumors but provides additional insights in a way patients can comprehend, promoting patient empowerment in their healthcare journey. HyperParameters Image shape: (150, 150, 3) Epochs: 40 Batch size: 128 Steps Per Epoch: 44 Validation steps: 10 \\nProject Report8\", metadata={'source': 'BTDA-Report.pdf', 'page': 7}),\n",
       " Document(page_content='Accuracy and F1 Score Class: Glioma Precision: 0.959 Recall: 0.937 F1-Score: 0.948 Class: Meningioma Precision: 0.936 Recall: 0.863 F1-Score: 0.898 Class: Notumor Precision: 0.933 Recall: 0.998 F1-Score: 0.964 Class: Pituitary Precision: 0.980 Recall: 0.990 F1-Score: 0.985 Accuracy: 0.950 \\nProject Report9', metadata={'source': 'BTDA-Report.pdf', 'page': 8}),\n",
       " Document(page_content=\"Methods used to improve accuracy To boost the accuracy of our models, we have implemented a few key strategies. Firstly, we have incorporated a Long Short-Term Memory (LSTM) layer into the later stages of our Convolutional Neural Network (CNN). This is especially helpful when we're dealing with sequential data. Additionally, we have prioritized hyperparameter tuning, carefully refining our model's configuration settings for the best possible performance. Lastly, we leveraged data augmentation techniques to increase the size and diversity of our training dataset. This helps minimize overfitting, improving our model's ability to handle new, unseen data eﬀectively. Results \\nProject Report10\", metadata={'source': 'BTDA-Report.pdf', 'page': 9}),\n",
       " Document(page_content=\"Conclusion In conclusion, the BTDA project presents a cutting-edge deep learning system that holds the potential to revolutionize brain tumor diagnosis and treatment. Its key strengths lie in secure user authentication, advanced AI-driven medical image analysis, streamlined patient case management, and the optimization of healthcare resource allocation. By utilizing a reliable and scalable cloud infrastructure, the BTDA creates a secure environment for sensitive medical data while facilitating real-time case tracking and collaboration between doctors and patients. This user-centric approach promises to deliver several significant benefits: •Enhanced Diagnostic Accuracy: AI-powered image analysis tools significantly increase the accuracy of diagnoses, leading to more targeted and eﬀective treatments. •Optimized Treatment Timelines: Streamlined case management reduces delays and accelerates the treatment process, ensuring patients receive critical care as quickly as possible. •Maximizing Medical Expertise: The BTDA platform eﬀectively distributes medical knowledge and expertise to areas where it's most urgently needed. Ultimately, the BTDA project has the potential to transform the landscape of brain tumor treatment, empowering both patients and healthcare providers with the best possible tools and technology for the fight against this challenging disease. \\nProject Report11\", metadata={'source': 'BTDA-Report.pdf', 'page': 10}),\n",
       " Document(page_content='References •Naseer, A., Yasir, T., Azhar, A., Shakeel, T., & Zafar, K. (2021). Computer-Aided Brain Tumor Diagnosis: Performance Evaluation of Deep Learner CNN Using Augmented Brain MRI. International journal of biomedical imaging, 2021, 5513500. https://doi.org/10.1155/2021/5513500 •Sarhan, A. (2020) Brain Tumor Classification in Magnetic Resonance Images Using Deep Learning and Wavelet Transform. Journal of Biomedical Science and Engineering, 13, 102-112. doi: 10.4236/jbise.2020.136010. •Mahmud, M.I.; Mamun, M.; Abdelgawad, A. A Deep Analysis of Brain Tumor Detection from MR Images Using Deep Learning Networks. Algorithms 2023, 16, 176. https://doi.org/10.3390/a16040176 •Saeedi, S., Rezayi, S., Keshavarz, H. et al. MRI-based brain tumor detection using convolutional deep learning methods and chosen machine learning techniques. BMC Med Inform Decis Mak 23, 16 (2023). https://doi.org/10.1186/s12911-023- 02114-6 •Xiong, S., Wu, G., Fan, X. et al. MRI-based brain tumor segmentation using FPGA- accelerated neural network. BMC Bioinformatics 22, 421 (2021). https://doi.org/10.1186/s12859-021-04347-6 •Rajinikanth, V., Kadry, S., & Nam, Y. (2021). Convolutional-neural-network assisted segmentation and SVM classification of brain tumor in clinical MRI slices. Information Technology and Control, 50 (2), 280-295. •Fouad, I. A. (2021). Developing a fully automated CAD tool for eﬀective and accurate detection of brain tumors in MRI images. International Journal of Computer Science and Information Security, 19(1), 1-9. •Anagun, Y. Smart brain tumor diagnosis system utilizing deep convolutional neural networks. Multimed Tools Appl 82, 44527-44553 (2023). https://doi.org/10.1007/s11042-023-15422-w Project Report12', metadata={'source': 'BTDA-Report.pdf', 'page': 11}),\n",
       " Document(page_content='•ZainEldin H, Gamel SA, El-Kenawy EM, Alharbi AH, Khafaga DS, Ibrahim A, Talaat FM. Brain Tumor Detection and Classification Using Deep Learning and Sine-Cosine Fitness Grey Wolf Optimization. Bioengineering (Basel). 2022 Dec 22;10(1):18. doi: 10.3390/bioengineering10010018. •Chen, T., Hu, L., Lu, Q., Xiao, F., Xu, H., Li, H., & Lu, L. (2023). A computer-aided diagnosis system for brain tumors based on artificial intelligence algorithms. Frontiers in Neuroscience, 17, 1120781. doi: 10.3389/fnins.2023.1120781 \\nProject Report13', metadata={'source': 'BTDA-Report.pdf', 'page': 12})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Create a document loader using the PyPDFLoader\n",
    "document_loader = PyPDFLoader('BTDA-Report.pdf')\n",
    "\n",
    "# Load the PDF document\n",
    "pages = document_loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Dimensionality Reduction using Haar Wavelet Transform: Theory & Implementation | by Saiyam Sakhuja | Apr, 2024 | Medium Open in app Sign up Sign in Write Sign up Sign in Dimensionality Reduction using Haar Wavelet Transform: Theory & Implementation Saiyam Sakhuja · Follow 4 min read · Apr 18, 2024 -- Listen Share Dimensionality reduction is a crucial technique in machine learning and data analysis, aimed at reducing the number of features or variables in a dataset while preserving its essential information. One powerful approach to dimensionality reduction is through the use of wavelet transforms, which decompose signals into localized frequency components. In this blog post, we’ll explore how to implement Haar Wavelet Transform, a simple yet effective wavelet transform, for dimensionality reduction in Python. Understanding Haar Wavelet Transform Introducing Haar Wavelet: Haar Wavelet is the simplest form of wavelet transform, named after mathematician Alfréd Haar. It consists of a', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='reduction in Python. Understanding Haar Wavelet Transform Introducing Haar Wavelet: Haar Wavelet is the simplest form of wavelet transform, named after mathematician Alfréd Haar. It consists of a single positive coefficient followed by a single negative coefficient, representing a step function and its negative counterpart, respectively. Despite its simplicity, Haar Wavelet has been widely used in signal and image processing due to its fast computation and ability to capture sharp transitions and edges. Wavelet Transform: Wavelet Transform is a mathematical operation that decomposes a signal into wavelets at different scales and positions. In the case of Haar Wavelet Transform, the signal is decomposed into Haar wavelets, which capture local features and discontinuities in the signal. Implementation in Python Setting Up the Environment: Before we dive into the implementation, make sure you have Python installed on your system along with the necessary libraries, such as NumPy and', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content=\"Implementation in Python Setting Up the Environment: Before we dive into the implementation, make sure you have Python installed on your system along with the necessary libraries, such as NumPy and PyWavelets. You can install PyWavelets using pip: pip install PyWavelets Now, let’s break down the Python code step-by-step: 1. Import Libraries: import numpy as np import pywt numpy (np) : This library provides powerful tools for numerical computations and array manipulation. It's essential for working with data in Python. pywt : This library specifically deals with wavelet transforms. We'll use its functions for applying DWT and thresholding. 2. Sample Data: # Sample data (replace with your actual data) data = np.random.rand( 8 , 20 ) This line creates a sample data matrix ( data ) with 8 rows and 20 columns. You'll replace this with your actual data in practice. The data is assumed to be numerical for wavelet transform to work effectively. 3. Define Threshold: # Define threshold\", metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content=\"8 rows and 20 columns. You'll replace this with your actual data in practice. The data is assumed to be numerical for wavelet transform to work effectively. 3. Define Threshold: # Define threshold (experiment with different values) threshold = 0.1 This line defines a threshold value ( threshold ) used for discarding wavelet coefficients. It controls the aggressiveness of dimensionality reduction. Experiment with different values (e.g., 0.05, 0.2) to find the optimal balance for your data. Higher thresholds discard more coefficients, leading to greater reduction but potentially losing information. 4. Apply Haar DWT to Rows: # Apply Haar DWT to each row coeff_list = [] for row in data: coeff = pywt.dwt(row, 'haar' ) coeff_list.append(coeff) We enter a loop that iterates through each row ( row ) of the data matrix. Inside the loop, pywt.dwt(row, 'haar') applies the Haar Wavelet Transform to the current row. This decomposes the row into approximation coefficients (capturing low-frequency\", metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content=\") of the data matrix. Inside the loop, pywt.dwt(row, 'haar') applies the Haar Wavelet Transform to the current row. This decomposes the row into approximation coefficients (capturing low-frequency information) and detail coefficients (capturing high-frequency information) at a single scale. The resulting coefficients ( coeff ) for each row are appended to a list coeff_list . 5. Apply Soft Thresholding: # Apply thresholding (soft thresholding example) thresholded_coeff_list = [] for coeff in coeff_list: thresholded_coeff = [pywt.threshold(c, mode= 'soft' , value=threshold) for c in coeff] thresholded_coeff_list.append(thresholded_coeff) Another loop iterates through the coeff_list containing the DWT coefficients for each row. Inside the loop, another list comprehension is used. It iterates through each element ( c ) within the current row's coefficients ( coeff ). pywt.threshold(c, mode='soft', value=threshold) applies soft thresholding to the coefficient c . This shrinks coefficients\", metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='through each element ( c ) within the current row\\'s coefficients ( coeff ). pywt.threshold(c, mode=\\'soft\\', value=threshold) applies soft thresholding to the coefficient c . This shrinks coefficients below the threshold value by the threshold amount, preserving some information but reducing their magnitude. The thresholded coefficients for each row are stored in a new list thresholded_coeff_list . 6. Reduced Dimension Data: # Reduced dimension data (keeping only approximation coefficients) reduced_data = np.array([coeff[ 0 ] for coeff in thresholded_coeff_list]) This line creates the final reduced-dimension data ( reduced_data ). It creates a NumPy array by selecting only the first element ( coeff[0] ) from each row in the thresholded_coeff_list . This first element represents the approximation coefficients, which capture the most important information in the data after applying the threshold. 7. Print Data Shapes: print ( \"Original data shape:\" , data.shape) print ( \"Reduced data', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='coefficients, which capture the most important information in the data after applying the threshold. 7. Print Data Shapes: print ( \"Original data shape:\" , data.shape) print ( \"Reduced data shape:\" , reduced_data.shape) This section simply prints the shapes of the original data and the reduced data. This helps visualize the achieved dimensionality reduction (reduction in the number of columns). By running this code, you’ll get the original data shape (8 rows, 20 columns) and the reduced data shape (8 rows, a smaller number of columns depending on the threshold). This indicates that the code successfully reduced the number of columns in your data while retaining the most significant information through the Haar Wavelet Transform and thresholding process. Output of the code with threshold = 0.1 Applications and Benefits Dimensionality Reduction: By selecting a subset of the approximation coefficients obtained from Haar Wavelet Transform, we can effectively reduce the dimensionality of', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='= 0.1 Applications and Benefits Dimensionality Reduction: By selecting a subset of the approximation coefficients obtained from Haar Wavelet Transform, we can effectively reduce the dimensionality of the dataset while preserving important features and patterns. This can lead to faster computation and improved performance in machine learning tasks. Signal and Image Processing: Haar Wavelet Transform is widely used in signal and image processing applications for tasks such as denoising, compression, and feature extraction. Its ability to capture local features and sharp transitions makes it well-suited for analyzing signals and images with complex structures. Conclusion Haar Wavelet Transform offers a powerful tool for dimensionality reduction and signal processing tasks in Python. By leveraging its simplicity and efficiency, we can effectively reduce the dimensionality of datasets while preserving important information and patterns. Whether you’re working on machine learning projects', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='its simplicity and efficiency, we can effectively reduce the dimensionality of datasets while preserving important information and patterns. Whether you’re working on machine learning projects or signal processing applications, Haar Wavelet Transform is a valuable technique to have in your toolkit. Sign up to discover human stories that deepen your understanding of the world. Free Distraction-free reading. No ads. Organize your knowledge with lists and highlights. Tell your story. Find your audience. Sign up for free Membership Access the best member-only stories. Support independent authors. Listen to audio narrations. Read offline. Join the Partner Program and earn for your writing. Try for $5/month Python Machine Learning Optimization Implementation Theory -- -- Follow Written by Saiyam Sakhuja 41 Followers Quantum Computing Enthusiast Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def extract_text_with_selenium(url):\n",
    "    try:\n",
    "        # Configure Selenium WebDriver (adjust for your setup)\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        service = Service(executable_path='/usr/local/bin/chromedriver')\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load (adjust wait time if needed)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        # Get the page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Extract text from the parsed HTML\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "        # Create a LangChain Document object\n",
    "        metadata = {\"source\": url}  \n",
    "        document = Document(page_content=text, metadata=metadata)\n",
    "        return document\n",
    "\n",
    "    except Exception as e:\n",
    "        # st.error(f\"Error extracting text from the webpage: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# \"https://medium.com/@deepanshut041/introduction-to-surf-speeded-up-robust-features-c7396d6e7c4e\", \"https://www.freecodecamp.org/news/beginners-guide-to-langchain/\"\n",
    "# Example Usage (assuming you have a list of URLs)\n",
    "urls = [\"https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2\"]\n",
    "documents = []\n",
    "for url in urls:\n",
    "    document = extract_text_with_selenium(url)\n",
    "    if document:\n",
    "        documents.append(document)\n",
    "\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
    "grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n",
    "Provide the binary score as aIJSON with a single key 'score' and no premable or explaination.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "\n",
    "You are an assistant for question-answe Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you dont know. \n",
    "Use three sentences maximum and keep the answer concise. Keep in mind that the goal is to provide a quick and accurate answer to the user's question.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "# print(prompt.format(context = \"The quick brown fox jumps over the lazy dog.\", question = \"What does the fox jump over?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chain.invoke({\n",
    "#     \"context\": \"The quick brown fox jumps over the lazy dog.\",\n",
    "#     \"question\": \"What does the fox jump over?\"\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages) == type(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# vectorstore = DocArrayInMemorySearch.from_documents(chunks, embedding=embeddings)\n",
    "vectorstore = Chroma.from_documents(documents=chunks, collection_name=\"rag-chroma\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Dimensionality Reduction using Haar Wavelet Transform: Theory & Implementation | by Saiyam Sakhuja | Apr, 2024 | Medium Open in app Sign up Sign in Write Sign up Sign in Dimensionality Reduction using Haar Wavelet Transform: Theory & Implementation Saiyam Sakhuja · Follow 4 min read · Apr 18, 2024 -- Listen Share Dimensionality reduction is a crucial technique in machine learning and data analysis, aimed at reducing the number of features or variables in a dataset while preserving its essential information. One powerful approach to dimensionality reduction is through the use of wavelet transforms, which decompose signals into localized frequency components. In this blog post, we’ll explore how to implement Haar Wavelet Transform, a simple yet effective wavelet transform, for dimensionality reduction in Python. Understanding Haar Wavelet Transform Introducing Haar Wavelet: Haar Wavelet is the simplest form of wavelet transform, named after mathematician Alfréd Haar. It consists of a', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content=\"8 rows and 20 columns. You'll replace this with your actual data in practice. The data is assumed to be numerical for wavelet transform to work effectively. 3. Define Threshold: # Define threshold (experiment with different values) threshold = 0.1 This line defines a threshold value ( threshold ) used for discarding wavelet coefficients. It controls the aggressiveness of dimensionality reduction. Experiment with different values (e.g., 0.05, 0.2) to find the optimal balance for your data. Higher thresholds discard more coefficients, leading to greater reduction but potentially losing information. 4. Apply Haar DWT to Rows: # Apply Haar DWT to each row coeff_list = [] for row in data: coeff = pywt.dwt(row, 'haar' ) coeff_list.append(coeff) We enter a loop that iterates through each row ( row ) of the data matrix. Inside the loop, pywt.dwt(row, 'haar') applies the Haar Wavelet Transform to the current row. This decomposes the row into approximation coefficients (capturing low-frequency\", metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='through each element ( c ) within the current row\\'s coefficients ( coeff ). pywt.threshold(c, mode=\\'soft\\', value=threshold) applies soft thresholding to the coefficient c . This shrinks coefficients below the threshold value by the threshold amount, preserving some information but reducing their magnitude. The thresholded coefficients for each row are stored in a new list thresholded_coeff_list . 6. Reduced Dimension Data: # Reduced dimension data (keeping only approximation coefficients) reduced_data = np.array([coeff[ 0 ] for coeff in thresholded_coeff_list]) This line creates the final reduced-dimension data ( reduced_data ). It creates a NumPy array by selecting only the first element ( coeff[0] ) from each row in the thresholded_coeff_list . This first element represents the approximation coefficients, which capture the most important information in the data after applying the threshold. 7. Print Data Shapes: print ( \"Original data shape:\" , data.shape) print ( \"Reduced data', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'}),\n",
       " Document(page_content='its simplicity and efficiency, we can effectively reduce the dimensionality of datasets while preserving important information and patterns. Whether you’re working on machine learning projects or signal processing applications, Haar Wavelet Transform is a valuable technique to have in your toolkit. Sign up to discover human stories that deepen your understanding of the world. Free Distraction-free reading. No ads. Organize your knowledge with lists and highlights. Tell your story. Find your audience. Sign up for free Membership Access the best member-only stories. Support independent authors. Listen to audio narrations. Read offline. Join the Partner Program and earn for your writing. Try for $5/month Python Machine Learning Optimization Implementation Theory -- -- Follow Written by Saiyam Sakhuja 41 Followers Quantum Computing Enthusiast Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams', metadata={'source': 'https://medium.com/@sakhujasaiyam/dimensionality-reduction-using-haar-wavelet-transform-a1678c5dc6e2'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"Haar wavelet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Haar Wavelet Transform is a powerful tool for dimensionality reduction and signal processing tasks in Python, commonly used in applications such. It applies the Haar Wavelet Transform to capture local features and sharp transitions in data, making it well-suited for analyzing complex signals and images. By selecting a subset of the approximation coefficients obtained from the Haar Wavelet Transform, we can effectively reduce the dimensionality of datasets while preserving important information and patterns.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "chain = (\n",
    "    {\"context\": itemgetter (\"question\") | retriever, \"question\": itemgetter (\"question\")} \n",
    "        | prompt \n",
    "        | model \n",
    "        | output_parser)\n",
    "\n",
    "print(chain.invoke({\"question\": \"What is a haar wavelet?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
